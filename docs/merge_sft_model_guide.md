# SFTæ¨¡å‹åˆå¹¶æŒ‡å—

## ğŸ¯ ä¸ºä»€ä¹ˆè¦å•ç‹¬åˆå¹¶SFTæ¨¡å‹ï¼Ÿ

### åŸæ¥çš„æµç¨‹ï¼ˆå¤æ‚ï¼‰
```
è®­ç»ƒDPOæ—¶:
åŸºç¡€æ¨¡å‹ + SFT LoRA â†’ (ä¸´æ—¶åˆå¹¶) â†’ è®­ç»ƒDPO â†’ ä¿å­˜å®Œæ•´æ¨¡å‹
â†‘ ä¸´æ—¶åˆå¹¶ï¼Œæœªä¿å­˜
```

é—®é¢˜ï¼š
- SFTå®Œæ•´æ¨¡å‹æ²¡æœ‰ä¿å­˜
- æ— æ³•å•ç‹¬è¯„ä¼°SFTæ¨¡å‹
- DPOè®­ç»ƒæ—¶éœ€è¦é‡å¤åˆå¹¶

### æ–°çš„æµç¨‹ï¼ˆæ¸…æ™°ï¼‰âœ¨
```
1. åˆå¹¶å¹¶ä¿å­˜SFTå®Œæ•´æ¨¡å‹
   åŸºç¡€æ¨¡å‹ + SFT LoRA â†’ SFTå®Œæ•´æ¨¡å‹ âœ…

2. è¯„ä¼°SFTå®Œæ•´æ¨¡å‹
   SFTå®Œæ•´æ¨¡å‹ â†’ è¯„ä¼° âœ…

3. åŸºäºSFTå®Œæ•´æ¨¡å‹è®­ç»ƒDPO
   SFTå®Œæ•´æ¨¡å‹ + DPO LoRA â†’ DPOå®Œæ•´æ¨¡å‹ âœ…
```

å¥½å¤„ï¼š
- âœ… SFTæ¨¡å‹å¯å•ç‹¬ä½¿ç”¨å’Œè¯„ä¼°
- âœ… è·¯å¾„å…³ç³»æ¸…æ™°
- âœ… DPOè®­ç»ƒé€»è¾‘ç®€å•

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨é»˜è®¤å‚æ•°

```bash
python scripts/merge_sft_model.py
```

**é»˜è®¤é…ç½®**:
- åŸºç¡€æ¨¡å‹: `Qwen2.5-1.5B-Instruct/qwen/Qwen2___5-1___5B-Instruct`
- SFT LoRA: `model_output/qwen2_5_1_5b_instruct_sft`
- è¾“å‡º: `model_output/qwen2_5_1_5b_instruct_sft_merged`

### æ–¹æ³•2: è‡ªå®šä¹‰å‚æ•°

```bash
python scripts/merge_sft_model.py \
    --base_model "path/to/base/model" \
    --sft_lora "path/to/sft/lora" \
    --output "path/to/output"
```

---

## ğŸ“Š é¢„æœŸè¾“å‡º

### æ§åˆ¶å°è¾“å‡º

```
======================================================================
SFTæ¨¡å‹åˆå¹¶å·¥å…·
======================================================================

ğŸ“‚ è·¯å¾„é…ç½®:
  åŸºç¡€æ¨¡å‹: /root/autodl-tmp/MedQA/Qwen2.5-1.5B-Instruct/...
  SFT LoRA: /root/autodl-tmp/MedQA/model_output/qwen2_5_1_5b_instruct_sft
  è¾“å‡ºè·¯å¾„: /root/autodl-tmp/MedQA/model_output/qwen2_5_1_5b_instruct_sft_merged

æ­¥éª¤1: åŠ è½½åŸºç¡€æ¨¡å‹...
âœ“ åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ

æ­¥éª¤2: åŠ è½½SFT LoRAé€‚é…å™¨...
âœ“ SFT LoRAåŠ è½½å®Œæˆ

ğŸ“Š æ¨¡å‹å‚æ•°:
  å¯è®­ç»ƒå‚æ•°: 18,874,368
  æ€»å‚æ•°: 1,543,746,560
  LoRAå‚æ•°å æ¯”: 1.22%

æ­¥éª¤3: åˆå¹¶SFT LoRAåˆ°åŸºç¡€æ¨¡å‹...
âœ“ LoRAå·²åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹

æ­¥éª¤4: ä¿å­˜å®Œæ•´æ¨¡å‹...
âœ“ æ¨¡å‹å·²ä¿å­˜

æ­¥éª¤5: éªŒè¯ä¿å­˜çš„æ–‡ä»¶...

ğŸ“Š ä¿å­˜çš„æ–‡ä»¶:
  model.safetensors: 3089.7 MB
  tokenizer.json: 11.1 MB
  ...

  æ€»å¤§å°: 3.02 GB

âœ… éªŒè¯é€šè¿‡: è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„åˆå¹¶æ¨¡å‹

======================================================================
âœ… SFTæ¨¡å‹åˆå¹¶å®Œæˆï¼
======================================================================
```

### ç›®å½•ç»“æ„

```
model_output/qwen2_5_1_5b_instruct_sft_merged/
â”œâ”€â”€ config.json                    # æ¨¡å‹é…ç½®
â”œâ”€â”€ generation_config.json         # ç”Ÿæˆé…ç½®
â”œâ”€â”€ model.safetensors             # å®Œæ•´æ¨¡å‹æƒé‡ (~3GB)
â”œâ”€â”€ tokenizer.json                # tokenizer
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ special_tokens_map.json
â””â”€â”€ ...
```

**å…³é”®æ ‡å¿—**:
- âœ… æœ‰ `model.safetensors` (å®Œæ•´æƒé‡)
- âŒ æ²¡æœ‰ `adapter_config.json` (ä¸æ˜¯LoRA)
- âœ… æ€»å¤§å° ~3GB (å®Œæ•´æ¨¡å‹)

---

## ğŸ“ åç»­æ­¥éª¤

### 1. è¯„ä¼°SFTå®Œæ•´æ¨¡å‹

æ›´æ–° `config/evaluation_config.yaml`:

```yaml
model:
  model_path: "model_output/qwen2_5_1_5b_instruct_sft_merged"
  is_lora: false  # å®Œæ•´æ¨¡å‹
  merge_lora: false
```

è¿è¡Œè¯„ä¼°:

```bash
python src/training/scripts/run_evaluation.py \
    --config_path config/evaluation_config.yaml
```

### 2. åŸºäºSFTå®Œæ•´æ¨¡å‹è®­ç»ƒDPO

æ›´æ–° `config/dpo_training_config.yaml`:

```yaml
model:
  base_model_path: "model_output/qwen2_5_1_5b_instruct_sft_merged"  # SFTå®Œæ•´æ¨¡å‹
  sft_checkpoint_path: null  # ä¸éœ€è¦äº†
  is_lora: false  # ç°åœ¨baseå°±æ˜¯å®Œæ•´çš„SFTæ¨¡å‹
  save_merged_dpo: true
```

è¿è¡ŒDPOè®­ç»ƒ:

```bash
python src/training/scripts/run_dpo_training.py
```

### 3. å¯¹æ¯”ä¸‰ä¸ªæ¨¡å‹

| æ¨¡å‹ | è·¯å¾„ | ç±»å‹ | è¯„ä¼°é…ç½® |
|------|------|------|----------|
| åŸºç¡€æ¨¡å‹ | `Qwen2.5-1.5B-Instruct/...` | å®Œæ•´ | `is_lora: false` |
| SFTæ¨¡å‹ | `qwen2_5_1_5b_instruct_sft_merged/` | å®Œæ•´ | `is_lora: false` |
| DPOæ¨¡å‹ | `qwen2_5_1_5b_dpo/` | å®Œæ•´ | `is_lora: false` |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ç£ç›˜ç©ºé—´

åˆå¹¶åçš„æ¨¡å‹çº¦ **3GB**ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ï¼š

```bash
# æ£€æŸ¥å¯ç”¨ç©ºé—´
df -h /root/autodl-tmp/MedQA/model_output/
```

### 2. å†…å­˜éœ€æ±‚

åˆå¹¶è¿‡ç¨‹éœ€è¦åŠ è½½å®Œæ•´æ¨¡å‹åˆ°å†…å­˜/GPUï¼š
- GPUå†…å­˜: å»ºè®® >= 8GB
- ç³»ç»Ÿå†…å­˜: å»ºè®® >= 16GB

### 3. æ—¶é—´æˆæœ¬

- åŠ è½½æ¨¡å‹: ~2-3åˆ†é’Ÿ
- åˆå¹¶: ~1-2åˆ†é’Ÿ
- ä¿å­˜: ~1-2åˆ†é’Ÿ
- **æ€»è®¡**: ~5-7åˆ†é’Ÿ

---

## ğŸ” æ•…éšœæ’æŸ¥

### é”™è¯¯: åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨

```bash
# æ£€æŸ¥è·¯å¾„
ls -la Qwen2.5-1.5B-Instruct/qwen/Qwen2___5-1___5B-Instruct/
```

### é”™è¯¯: SFT LoRAè·¯å¾„ä¸å­˜åœ¨

```bash
# æ£€æŸ¥SFT LoRA
ls -la model_output/qwen2_5_1_5b_instruct_sft/adapter_config.json
```

### é”™è¯¯: CUDA out of memory

é™ä½æ¨¡å‹ç²¾åº¦ï¼š

ä¿®æ”¹è„šæœ¬ä¸­çš„ï¼š
```python
torch_dtype=torch.float16  # æ”¹ä¸º torch.float32 æˆ– torch.bfloat16
```

æˆ–ä½¿ç”¨CPUï¼ˆæ…¢ä½†ç¨³å®šï¼‰ï¼š
```python
device_map="cpu"  # æ”¹ä¸º cpu
```

### è­¦å‘Š: ä»ç„¶æ˜¯LoRAé€‚é…å™¨

å¦‚æœçœ‹åˆ°æ­¤è­¦å‘Šï¼Œè¯´æ˜åˆå¹¶å¤±è´¥ã€‚æ£€æŸ¥ï¼š
1. PEFTç‰ˆæœ¬: `pip show peft`
2. æ˜¯å¦è°ƒç”¨äº† `merge_and_unload()`

---

## ğŸ“š å‚è€ƒ

- [æ¨¡å‹åˆå¹¶åŸç†](./dpo_model_guide.md)
- [DPOè®­ç»ƒé…ç½®](./dpo_training_config.md)
- [è¯„ä¼°é…ç½®](./evaluation_config_guide.md)

---

**æ›´æ–°æ—¶é—´**: 2026-02-01  
**ç‰ˆæœ¬**: v1.0
