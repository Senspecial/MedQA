"""
å®Œæ•´çš„äº¤äº’å¼ RAG ç³»ç»Ÿ
æ”¯æŒæ–‡æ¡£åŠ è½½ã€å‘é‡ç´¢å¼•æ„å»ºã€äº¤äº’å¼é—®ç­”
"""
import os
import sys
import time
from typing import List, Dict, Any

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ python path ä¸­
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from src.rag.rag_pipeline import RAGPipeline
from src.models.qwen_model import Qwen2Model
from src.knowledge_base.document_loader import DocumentLoader
from src.utils.logger import setup_logger

# è®¾ç½®æ—¥å¿—
logger = setup_logger("rag_demo")

def load_documents_from_source(source_type: str = "builtin") -> List[Dict[str, Any]]:
    """
    ä»ä¸åŒæ¥æºåŠ è½½æ–‡æ¡£
    
    Args:
        source_type: æ–‡æ¡£æ¥æºç±»å‹ ("builtin", "file", "directory")
    
    Returns:
        æ–‡æ¡£å­—å…¸åˆ—è¡¨
    """
    if source_type == "builtin":
        # å†…ç½®æµ‹è¯•æ–‡æ¡£
        return [
        {
            "id": "doc_001",
                "content": "æ„Ÿå†’é€šå¸¸ç”±ç—…æ¯’å¼•èµ·ï¼Œç—‡çŠ¶åŒ…æ‹¬é¼»å¡ã€æµæ¶•ã€å’³å—½ã€å–‰å’™ç—›ç­‰ã€‚ä¼‘æ¯å’Œå¤šå–æ°´æ˜¯ä¸»è¦çš„æ²»ç–—å»ºè®®ã€‚è½»åº¦æ„Ÿå†’é€šå¸¸7-10å¤©å¯è‡ªæ„ˆã€‚",
                "metadata": {"source": "å¸¸è§ç—…æŒ‡å—", "title": "æ„Ÿå†’æ¦‚è¿°", "category": "å¸¸è§ç—…"}
        },
        {
            "id": "doc_002",
                "content": "é«˜è¡€å‹æ‚£è€…åº”æ§åˆ¶ç›åˆ†æ‘„å…¥ï¼Œå®šæœŸç›‘æµ‹è¡€å‹ã€‚å¸¸ç”¨è¯ç‰©åŒ…æ‹¬åˆ©å°¿å‰‚ã€é’™é€šé“é˜»æ»å‰‚ã€ACEIç±»è¯ç‰©ç­‰ã€‚ç”Ÿæ´»æ–¹å¼å¹²é¢„åŒ…æ‹¬æˆ’çƒŸé™é…’ã€é€‚åº¦è¿åŠ¨ã€å‡è½»ä½“é‡ã€‚",
                "metadata": {"source": "æ…¢æ€§ç—…ç®¡ç†", "title": "é«˜è¡€å‹æŠ¤ç†", "category": "æ…¢æ€§ç—…"}
        },
        {
            "id": "doc_003",
                "content": "ç³–å°¿ç—…é¥®é£Ÿæ§åˆ¶éå¸¸é‡è¦ï¼Œåº”å‡å°‘ç³–åˆ†å’Œç²¾åˆ¶ç¢³æ°´åŒ–åˆç‰©çš„æ‘„å…¥ï¼Œå¢åŠ è†³é£Ÿçº¤ç»´ã€‚æ¨èä½GIé£Ÿç‰©ï¼Œå¦‚å…¨è°·ç‰©ã€è±†ç±»ã€è”¬èœç­‰ã€‚",
                "metadata": {"source": "é¥®é£Ÿå¥åº·", "title": "ç³–å°¿ç—…é¥®é£Ÿ", "category": "æ…¢æ€§ç—…"}
            },
            {
                "id": "doc_004",
                "content": "å¿ƒè„ç—…çš„é¢„é˜²éœ€è¦æ§åˆ¶å±é™©å› ç´ ï¼ŒåŒ…æ‹¬é«˜è¡€å‹ã€é«˜è¡€è„‚ã€ç³–å°¿ç—…ã€å¸çƒŸç­‰ã€‚å®šæœŸä½“æ£€å’Œå¿ƒç”µå›¾æ£€æŸ¥å¾ˆé‡è¦ã€‚",
                "metadata": {"source": "å¿ƒè¡€ç®¡ç–¾ç—…", "title": "å¿ƒè„ç—…é¢„é˜²", "category": "æ…¢æ€§ç—…"}
            },
            {
                "id": "doc_005",
                "content": "å¤±çœ çš„æ²»ç–—å¯ä»¥ä»æ”¹å–„ç¡çœ ä¹ æƒ¯å¼€å§‹ï¼Œå¦‚å›ºå®šä½œæ¯æ—¶é—´ã€é¿å…ç¡å‰ä½¿ç”¨ç”µå­è®¾å¤‡ã€ä¿æŒå§å®¤å®‰é™èˆ’é€‚ã€‚å¿…è¦æ—¶å¯è€ƒè™‘è®¤çŸ¥è¡Œä¸ºç–—æ³•æˆ–è¯ç‰©æ²»ç–—ã€‚",
                "metadata": {"source": "ç¡çœ å¥åº·", "title": "å¤±çœ æ²»ç–—", "category": "å¸¸è§ç—…"}
            },
            {
                "id": "doc_006",
                "content": "æ–°å† ç–«è‹—æ¥ç§å¯ä»¥æœ‰æ•ˆé¢„é˜²é‡ç—‡å’Œæ­»äº¡ã€‚å¸¸è§å‰¯ä½œç”¨åŒ…æ‹¬æ³¨å°„éƒ¨ä½ç–¼ç—›ã€å‘çƒ­ã€ç–²åŠ³ç­‰ï¼Œé€šå¸¸åœ¨1-2å¤©å†…ç¼“è§£ã€‚",
                "metadata": {"source": "ç–«è‹—æŒ‡å—", "title": "æ–°å† ç–«è‹—", "category": "é¢„é˜²"}
            },
            {
                "id": "doc_007",
                "content": "éª¨è´¨ç–æ¾ç—‡æ‚£è€…åº”å¢åŠ é’™å’Œç»´ç”Ÿç´ Dçš„æ‘„å…¥ï¼Œè¿›è¡Œé€‚åº¦çš„è´Ÿé‡è¿åŠ¨ã€‚é«˜å±äººç¾¤åº”å®šæœŸè¿›è¡Œéª¨å¯†åº¦æ£€æµ‹ã€‚",
                "metadata": {"source": "éª¨éª¼å¥åº·", "title": "éª¨è´¨ç–æ¾", "category": "æ…¢æ€§ç—…"}
        }
    ]
    
    elif source_type == "file":
        print("\nè¯·è¾“å…¥æ–‡æ¡£æ–‡ä»¶è·¯å¾„ (æ”¯æŒ: PDF, TXT, DOCX, MD, JSON ç­‰):")
        file_path = input("æ–‡ä»¶è·¯å¾„: ").strip()
        
        if not os.path.exists(file_path):
            print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        
        loader = DocumentLoader()
        try:
            langchain_docs = loader.load_document(file_path)
            documents = []
            for i, doc in enumerate(langchain_docs):
                documents.append({
                    "id": f"doc_{i:03d}",
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })
            return documents
        except Exception as e:
            print(f"âœ— åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    return []


def interactive_query_loop(rag: RAGPipeline, use_llm: bool = False):
    """
    äº¤äº’å¼æŸ¥è¯¢å¾ªç¯
    
    Args:
        rag: RAGæµæ°´çº¿å®ä¾‹
        use_llm: æ˜¯å¦ä½¿ç”¨LLMç”Ÿæˆå›ç­”
    """
    print("\n" + "="*70)
    print("ğŸ¤– äº¤äº’å¼ RAG é—®ç­”ç³»ç»Ÿ")
    print("="*70)
    print("\nä½¿ç”¨è¯´æ˜:")
    print("  - è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
    print("  - è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("  - è¾“å…¥ 'stats' æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
    print("  - è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
    print("="*70)
    
    query_count = 0
    
    while True:
        print("\n" + "-"*70)
        user_input = input("\nğŸ’¬ æ‚¨çš„é—®é¢˜: ").strip()
        
        if not user_input:
            continue
        
        # å¤„ç†ç‰¹æ®Šå‘½ä»¤
        if user_input.lower() in ['exit', 'quit', 'q']:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        
        elif user_input.lower() == 'help':
            print("\nğŸ“– å¸®åŠ©ä¿¡æ¯:")
            print("  exit/quit - é€€å‡ºç³»ç»Ÿ")
            print("  stats     - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
            print("  help      - æ˜¾ç¤ºæ­¤å¸®åŠ©")
            continue
        
        elif user_input.lower() == 'stats':
            print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
            print(f"  æŸ¥è¯¢æ¬¡æ•°: {query_count}")
            print(f"  æ–‡æ¡£æ•°é‡: {len(rag.retriever.documents) if hasattr(rag.retriever, 'documents') else 'æœªçŸ¥'}")
            print(f"  ç´¢å¼•ç±»å‹: {rag.retriever_type}")
            print(f"  ä½¿ç”¨LLM: {'æ˜¯' if use_llm else 'å¦'}")
            continue
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query_count += 1
        print(f"\nğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
        
        try:
            start_time = time.time()
            
            # æ£€ç´¢æ–‡æ¡£
            retrieved_docs = rag.query(user_input, top_k=3)
            retrieval_time = time.time() - start_time
            
            if not retrieved_docs:
                print("âš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                continue
            
            print(f"âœ“ æ£€ç´¢å®Œæˆ ({retrieval_time:.3f}ç§’)")
            print(f"\nğŸ“„ æ‰¾åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£:\n")
            
            # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
            for i, doc in enumerate(retrieved_docs):
                score = doc.get('score', 0)
                content = doc.get('content', doc.get('text', ''))
                metadata = doc.get('metadata', {})
                title = metadata.get('title', 'æœªå‘½åæ–‡æ¡£')
                
                print(f"  [{i+1}] ğŸ“Œ {title} (ç›¸å…³åº¦: {score:.4f})")
                print(f"      {content[:100]}...")
                print()
            
            # å¦‚æœå¯ç”¨LLMï¼Œç”Ÿæˆå›ç­”
            if use_llm:
                print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
                try:
                    gen_start = time.time()
                    response = rag.generate_response(user_input, top_k=3)
                    gen_time = time.time() - gen_start
                    
                    print("\n" + "="*70)
                    print("ğŸ’¡ AI å›ç­”:")
                    print("-"*70)
                    
                    # æå–å›ç­”å†…å®¹
                    if isinstance(response, dict):
                        answer = response.get('answer', response.get('response', str(response)))
                    else:
                        answer = str(response)
                    
                    print(answer)
                    print("-"*70)
                    print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {gen_time:.2f}ç§’")
                    print("="*70)
                    
                except Exception as e:
                    print(f"âœ— ç”Ÿæˆå›ç­”å¤±è´¥: {e}")
            else:
                print("ğŸ’¡ æç¤º: å¯ç”¨LLMå¯ä»¥è·å¾—æ›´è¯¦ç»†çš„å›ç­”")
        
        except Exception as e:
            print(f"âœ— æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„RAGç³»ç»Ÿåˆå§‹åŒ–å’Œäº¤äº’æµç¨‹"""
    
    print("="*70)
    print("ğŸš€ å®Œæ•´ RAG ç³»ç»Ÿ - äº¤äº’å¼é—®ç­”")
    print("="*70)

    # ========== é…ç½®å‚æ•° ==========
    EMBEDDING_MODEL = "moka-ai/m3e-base"
    LLM_MODEL_PATH = "save/Qwen2_5-1_5B-medqa-merged"
    INDEX_PATH = "data/indexes/rag_demo"
    
    # ========== é˜¶æ®µ 1: æ–‡æ¡£å‡†å¤‡ ==========
    print("\nã€é˜¶æ®µ 1/4ã€‘æ–‡æ¡£å‡†å¤‡")
    print("-"*70)
    
    print("\né€‰æ‹©æ–‡æ¡£æ¥æº:")
    print("  1. ä½¿ç”¨å†…ç½®æµ‹è¯•æ–‡æ¡£ (7ä¸ªåŒ»ç–—çŸ¥è¯†æ–‡æ¡£)")
    print("  2. ä»æ–‡ä»¶åŠ è½½ (PDF, TXT, DOCX, JSONç­‰)")
    
    choice = input("\nè¯·é€‰æ‹© (1/2, é»˜è®¤1): ").strip() or "1"
    
    if choice == "2":
        documents = load_documents_from_source("file")
        if not documents:
            print("ä½¿ç”¨å†…ç½®æ–‡æ¡£ä½œä¸ºå¤‡é€‰")
            documents = load_documents_from_source("builtin")
    else:
        documents = load_documents_from_source("builtin")
    
    print(f"âœ“ å·²å‡†å¤‡ {len(documents)} ä¸ªæ–‡æ¡£")
    
    # ========== é˜¶æ®µ 2: åˆå§‹åŒ–RAGæµæ°´çº¿ ==========
    print("\nã€é˜¶æ®µ 2/4ã€‘åˆå§‹åŒ– RAG æµæ°´çº¿")
    print("-"*70)
    print(f"ğŸ“¦ åµŒå…¥æ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"ğŸ” æ£€ç´¢å™¨ç±»å‹: KNN (FAISS)")
    print(f"ğŸ’¾ ç´¢å¼•è·¯å¾„: {INDEX_PATH}")
    
    try:
    rag = RAGPipeline(
        retriever_type="knn",
        embedding_model_name=EMBEDDING_MODEL,
        index_path=INDEX_PATH,
        top_k=3
    )
        print("âœ“ RAG æµæ°´çº¿åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # ========== é˜¶æ®µ 3: æ„å»ºå‘é‡ç´¢å¼• ==========
    print("\nã€é˜¶æ®µ 3/4ã€‘æ„å»ºå‘é‡ç´¢å¼•")
    print("-"*70)
    
    os.makedirs(os.path.dirname(INDEX_PATH) if os.path.dirname(INDEX_PATH) else "data/indexes", exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç´¢å¼•
    if os.path.exists(INDEX_PATH) and os.path.exists(f"{INDEX_PATH}/faiss_index.bin"):
        use_cache = input("æ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œæ˜¯å¦ä½¿ç”¨ï¼Ÿ(Y/n): ").strip().lower()
        if use_cache != 'n':
            try:
                print("æ­£åœ¨åŠ è½½å·²æœ‰ç´¢å¼•...")
                # æ³¨æ„ï¼šéœ€è¦å…ˆæ·»åŠ æ–‡æ¡£æ‰èƒ½æ­£ç¡®åŠ è½½
                rag.update_retriever_index(documents, save_path=INDEX_PATH)
                print("âœ“ ç´¢å¼•åŠ è½½æˆåŠŸ")
            except:
                print("åŠ è½½å¤±è´¥ï¼Œé‡æ–°æ„å»ºç´¢å¼•...")
                rag.update_retriever_index(documents, save_path=INDEX_PATH)
                print("âœ“ ç´¢å¼•æ„å»ºå®Œæˆ")
        else:
            rag.update_retriever_index(documents, save_path=INDEX_PATH)
            print("âœ“ ç´¢å¼•æ„å»ºå®Œæˆ")
    else:
        print("æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...")
        rag.update_retriever_index(documents, save_path=INDEX_PATH)
        print("âœ“ ç´¢å¼•æ„å»ºå®Œæˆ")
    
    # ========== é˜¶æ®µ 4: LLMåŠ è½½ (å¯é€‰) ==========
    print("\nã€é˜¶æ®µ 4/4ã€‘LLM åŠ è½½ (å¯é€‰)")
    print("-"*70)
    print("æ˜¯å¦åŠ è½½ LLM è¿›è¡Œæ™ºèƒ½å›ç­”ç”Ÿæˆï¼Ÿ")
    print("  - é€‰æ‹© 'y': åŠ è½½åŒ»ç–—æ¨¡å‹ï¼Œç”Ÿæˆè¯¦ç»†å›ç­” (éœ€è¦GPU)")
    print("  - é€‰æ‹© 'n': ä»…è¿›è¡Œæ–‡æ¡£æ£€ç´¢ (æ›´å¿«ï¼Œæ— éœ€GPU)")
    
    use_llm_choice = input("\næ˜¯å¦åŠ è½½ LLMï¼Ÿ(y/N): ").strip().lower()
    use_llm = False
    
    if use_llm_choice == 'y':
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {LLM_MODEL_PATH}")
        print("â³ åŠ è½½ä¸­ï¼Œè¯·ç¨å€™...")
        
        try:
        model = Qwen2Model(
            model_path=LLM_MODEL_PATH,
            device="cuda",
            load_in_4bit=True, 
            trust_remote_code=True
        )
        rag.set_model(model)
            print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
            use_llm = True
    except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("å°†ä»¥ä»…æ£€ç´¢æ¨¡å¼è¿è¡Œ")
            use_llm = False
    else:
        print("âœ“ å°†ä»¥ä»…æ£€ç´¢æ¨¡å¼è¿è¡Œ")
    
    # ========== è¿›å…¥äº¤äº’å¼æŸ¥è¯¢å¾ªç¯ ==========
    interactive_query_loop(rag, use_llm=use_llm)

if __name__ == "__main__":
    main()
#python -m src.rag.rag_demo