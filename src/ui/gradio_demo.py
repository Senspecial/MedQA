import gradio as gr
from llmtuner import ChatModel
from llmtuner.extras.misc import torch_gc

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…åœ¨å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡ï¼‰
chat_model = ChatModel()
INIT_HISTORY = [('ç°åœ¨ä½ æ˜¯ä¸€åä¸“ä¸šçš„ä¸­åŒ»åŒ»ç”Ÿ...ï¼ˆåŒåŸå§‹åˆå§‹åŒ–å†å²ï¼‰')]

def clear_history():
    global chat_model
    torch_gc()
    return INIT_HISTORY.copy()

def respond(message, history):
    history = history or INIT_HISTORY.copy()
    
    # æµå¼ç”Ÿæˆå“åº”
    full_response = ""
    for new_text in chat_model.stream_chat(message, history):
        full_response += new_text
        yield full_response
    
    # æ›´æ–°å†å²ï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰

with gr.Blocks(title="ä¸­åŒ»èŠå¤©æœºå™¨äºº") as demo:
    gr.Markdown("## ğŸ§‘âš•ï¸ ä¸­åŒ»æ™ºèƒ½åŠ©æ‰‹")
    gr.Markdown("è¾“å…¥æ‚¨çš„ä¸­åŒ»é—®é¢˜ï¼Œä½¿ç”¨ä¸‹æ–¹æŒ‰é’®æ¸…é™¤å†å²")
    
    chat = gr.ChatInterface(
        respond,
        chatbot=gr.Chatbot(height=500),
        additional_inputs=[
            gr.State(INIT_HISTORY.copy())
        ],
        retry_btn=None,
        undo_btn=None
    )
    
    with gr.Row():
        clear_btn = gr.Button("ğŸ§¹ æ¸…é™¤å†å²")
        clear_btn.click(
            fn=clear_history,
            outputs=chat.chatbot
        )

if __name__ == "__main__":
    demo.queue().launch()