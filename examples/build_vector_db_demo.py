"""
å‘é‡æ•°æ®åº“æ„å»ºè¯¦ç»†æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„æ–‡æ¡£åŠ è½½ã€å‘é‡åŒ–ã€ç´¢å¼•æ„å»ºè¿‡ç¨‹
"""
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.knowledge_base.document_loader import DocumentLoader
from src.knowledge_base.embedding_manager import EmbeddingManager
from src.knowledge_base.retrieval.knn_retriever import KNNRetriever
from langchain_core.documents import Document


def demo_step_by_step():
    """é€æ­¥æ¼”ç¤ºå‘é‡æ•°æ®åº“æ„å»º"""
    
    print("="*70)
    print("å‘é‡æ•°æ®åº“æ„å»ºè¯¦ç»†æ¼”ç¤º")
    print("="*70)
    
    # ============== é˜¶æ®µ 1: å‡†å¤‡æ–‡æ¡£ ==============
    print("\nã€é˜¶æ®µ 1ã€‘å‡†å¤‡æ–‡æ¡£æ•°æ®")
    print("-"*70)
    
    # æ–¹å¼1: ç›´æ¥åˆ›å»ºDocumentå¯¹è±¡
    documents = [
        Document(
            page_content="é«˜è¡€å‹æ˜¯ä¸€ç§å¸¸è§çš„æ…¢æ€§ç–¾ç—…ï¼Œéœ€è¦é•¿æœŸç®¡ç†ã€‚ä¸»è¦æ²»ç–—æ–¹æ³•åŒ…æ‹¬è¯ç‰©æ²»ç–—å’Œç”Ÿæ´»æ–¹å¼æ”¹å˜ã€‚",
            metadata={"doc_id": "doc_001", "title": "é«˜è¡€å‹ç®¡ç†", "category": "æ…¢æ€§ç—…"}
        ),
        Document(
            page_content="ç³–å°¿ç—…æ‚£è€…åº”æ³¨æ„é¥®é£Ÿæ§åˆ¶ï¼Œå‡å°‘ç³–åˆ†æ‘„å…¥ï¼Œå¢åŠ è†³é£Ÿçº¤ç»´ã€‚å®šæœŸç›‘æµ‹è¡€ç³–æ°´å¹³å¾ˆé‡è¦ã€‚",
            metadata={"doc_id": "doc_002", "title": "ç³–å°¿ç—…æŠ¤ç†", "category": "æ…¢æ€§ç—…"}
        ),
        Document(
            page_content="æ„Ÿå†’é€šå¸¸ç”±ç—…æ¯’å¼•èµ·ï¼Œç—‡çŠ¶åŒ…æ‹¬å‘çƒ­ã€å’³å—½ã€æµæ¶•ã€‚å¤šä¼‘æ¯å¤šå–æ°´æœ‰åŠ©äºæ¢å¤ã€‚",
            metadata={"doc_id": "doc_003", "title": "æ„Ÿå†’æ²»ç–—", "category": "å¸¸è§ç—…"}
        )
    ]
    
    print(f"âœ“ åˆ›å»ºäº† {len(documents)} ä¸ªæ–‡æ¡£å¯¹è±¡")
    for i, doc in enumerate(documents):
        print(f"  æ–‡æ¡£ {i+1}: {doc.metadata['title']} | å†…å®¹é•¿åº¦: {len(doc.page_content)} å­—ç¬¦")
    
    # æ–¹å¼2: ä»æ–‡ä»¶åŠ è½½ (æ¼”ç¤º)
    print("\næç¤º: ä¹Ÿå¯ä»¥ä½¿ç”¨ DocumentLoader ä»æ–‡ä»¶åŠ è½½:")
    print("  loader = DocumentLoader()")
    print("  docs = loader.load_document('path/to/file.pdf')")
    print("  æ”¯æŒ: PDF, TXT, DOCX, MD, CSV, XLSX, HTML, JSON")
    
    # ============== é˜¶æ®µ 2: åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ ==============
    print("\nã€é˜¶æ®µ 2ã€‘åˆå§‹åŒ–åµŒå…¥æ¨¡å‹")
    print("-"*70)
    
    embedding_model = "moka-ai/m3e-base"  # ä¸­æ–‡åµŒå…¥æ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {embedding_model}")
    print("æç¤º: é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œåç»­ä¼šä½¿ç”¨ç¼“å­˜")
    
    embedding_manager = EmbeddingManager(
        embedding_model_name=embedding_model,
        cache_dir="embedding_cache",  # ç¼“å­˜ç›®å½•
        use_cache=True  # å¯ç”¨ç¼“å­˜
    )
    
    print(f"âœ“ åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ")
    print(f"  æ¨¡å‹åç§°: {embedding_model}")
    print(f"  å‘é‡ç»´åº¦: {embedding_manager.get_embedding_dimension()}")
    print(f"  ç¼“å­˜ç›®å½•: embedding_cache/")
    
    # ============== é˜¶æ®µ 3: ç”ŸæˆåµŒå…¥å‘é‡ ==============
    print("\nã€é˜¶æ®µ 3ã€‘ç”Ÿæˆæ–‡æ¡£åµŒå…¥å‘é‡")
    print("-"*70)
    
    print("æ­£åœ¨å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡...")
    embeddings_dict = embedding_manager.embed_documents(documents)
    
    print(f"âœ“ ç”Ÿæˆäº† {len(embeddings_dict)} ä¸ªåµŒå…¥å‘é‡")
    for doc_id, embedding in embeddings_dict.items():
        print(f"  {doc_id}: å‘é‡ç»´åº¦ {len(embedding)}, å‰5ç»´: {embedding[:5]}")
    
    # ============== é˜¶æ®µ 4: æ„å»ºFAISSç´¢å¼• ==============
    print("\nã€é˜¶æ®µ 4ã€‘æ„å»º FAISS å‘é‡ç´¢å¼•")
    print("-"*70)
    
    print("æ­£åœ¨åˆå§‹åŒ– KNN æ£€ç´¢å™¨...")
    retriever = KNNRetriever(
        embedding_manager=embedding_manager,
        index_type="Flat"  # ä½¿ç”¨ç²¾ç¡®æœç´¢
    )
    
    print("æ­£åœ¨æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•...")
    retriever.add_documents(documents)
    
    print(f"âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
    print(f"  ç´¢å¼•ç±»å‹: FAISS Flat (ç²¾ç¡®æœç´¢)")
    print(f"  æ–‡æ¡£æ•°é‡: {len(retriever.documents)}")
    print(f"  å‘é‡ç»´åº¦: {retriever.dimension}")
    
    # ============== é˜¶æ®µ 5: æµ‹è¯•æ£€ç´¢ ==============
    print("\nã€é˜¶æ®µ 5ã€‘æµ‹è¯•å‘é‡æ£€ç´¢")
    print("-"*70)
    
    test_queries = [
        "å¦‚ä½•æ§åˆ¶é«˜è¡€å‹ï¼Ÿ",
        "ç³–å°¿ç—…é¥®é£Ÿè¦æ³¨æ„ä»€ä¹ˆï¼Ÿ",
        "æ„Ÿå†’äº†æ€ä¹ˆåŠï¼Ÿ"
    ]
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        
        # æ–¹æ³•1: ä½¿ç”¨search (è¿”å›Documentå’Œscore)
        results = retriever.search(query, top_k=2)
        
        for i, (doc, score) in enumerate(results):
            title = doc.metadata.get('title', 'æœªçŸ¥')
            content = doc.page_content[:40]
            print(f"  [{i+1}] ç›¸ä¼¼åº¦: {score:.4f} | {title}")
            print(f"      {content}...")
    
    # ============== é˜¶æ®µ 6: ä¿å­˜ç´¢å¼• ==============
    print("\nã€é˜¶æ®µ 6ã€‘ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜")
    print("-"*70)
    
    save_dir = "data/indexes/demo_kb"
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"æ­£åœ¨ä¿å­˜ç´¢å¼•åˆ°: {save_dir}")
    retriever.save(save_dir)
    
    print("âœ“ ç´¢å¼•ä¿å­˜å®Œæˆ")
    print(f"  ç´¢å¼•æ–‡ä»¶: {save_dir}/faiss_index.bin")
    print(f"  æ–‡æ¡£æ•°æ®: {save_dir}/documents.pkl")
    print(f"  é…ç½®æ–‡ä»¶: {save_dir}/config.json")
    print(f"  æ–‡æ¡£ID: {save_dir}/document_ids.json")
    
    # è·å–æ–‡ä»¶å¤§å°
    if os.path.exists(f"{save_dir}/faiss_index.bin"):
        index_size = os.path.getsize(f"{save_dir}/faiss_index.bin") / 1024
        docs_size = os.path.getsize(f"{save_dir}/documents.pkl") / 1024
        print(f"  æ–‡ä»¶å¤§å°: faiss_index.bin={index_size:.1f}KB, documents.pkl={docs_size:.1f}KB")
    else:
        print("  æ³¨æ„: ç´¢å¼•æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½ä¿å­˜å¤±è´¥")
    
    # ============== é˜¶æ®µ 7: åŠ è½½ç´¢å¼• ==============
    print("\nã€é˜¶æ®µ 7ã€‘ä»ç£ç›˜åŠ è½½ç´¢å¼•")
    print("-"*70)
    
    print("åˆ›å»ºæ–°çš„æ£€ç´¢å™¨å¹¶åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•...")
    new_retriever = KNNRetriever(
        embedding_manager=embedding_manager,
        index_type="Flat"
    )
    new_retriever.load(save_dir)
    
    print(f"âœ“ ç´¢å¼•åŠ è½½å®Œæˆ")
    print(f"  æ–‡æ¡£æ•°é‡: {len(new_retriever.documents)}")
    print(f"  å‘é‡ç»´åº¦: {new_retriever.dimension}")
    
    # æµ‹è¯•åŠ è½½çš„ç´¢å¼•
    print("\næµ‹è¯•åŠ è½½çš„ç´¢å¼•:")
    query = "é«˜è¡€å‹æ²»ç–—"
    results = new_retriever.search(query, top_k=1)
    doc, score = results[0]
    print(f"  æŸ¥è¯¢: {query}")
    print(f"  ç»“æœ: {doc.metadata['title']} (ç›¸ä¼¼åº¦: {score:.4f})")
    
    print("\n" + "="*70)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("="*70)
    
    return retriever


def demo_from_file():
    """ä»æ–‡ä»¶æ„å»ºå‘é‡æ•°æ®åº“çš„æ¼”ç¤º"""
    
    print("\n\n")
    print("="*70)
    print("ã€è¡¥å……ã€‘ä»æ–‡ä»¶æ„å»ºå‘é‡æ•°æ®åº“")
    print("="*70)
    
    # ç¤ºä¾‹ï¼šå¦‚æœæœ‰JSONæ–‡ä»¶
    json_file = "dpo.json"  # æ‚¨çš„DPOæ•°æ®é›†
    
    if os.path.exists(json_file):
        print(f"\næ­£åœ¨ä»æ–‡ä»¶åŠ è½½: {json_file}")
        
        try:
            loader = DocumentLoader()
            documents = loader.load_document(json_file)
            
            print(f"âœ“ åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æ¡£
            print("\nå‰3ä¸ªæ–‡æ¡£ç¤ºä¾‹:")
            for i, doc in enumerate(documents[:3]):
                content = doc.page_content[:60].replace('\n', ' ')
                print(f"  [{i+1}] é•¿åº¦: {len(doc.page_content)} | {content}...")
            
            # å¯ä»¥ç»§ç»­ä½¿ç”¨ä¸Šé¢çš„æµç¨‹æ„å»ºç´¢å¼•
            print("\næç¤º: ä½¿ç”¨ä¸Šé¢çš„æµç¨‹å¯ä»¥ä¸ºè¿™äº›æ–‡æ¡£æ„å»ºç´¢å¼•")
        except Exception as e:
            print(f"âœ— åŠ è½½å¤±è´¥: {e}")
    else:
        print(f"\næ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        print("æ¼”ç¤ºè·³è¿‡")


if __name__ == "__main__":
    # è¿è¡Œè¯¦ç»†æ¼”ç¤º
    retriever = demo_step_by_step()
    
    # ä»æ–‡ä»¶åŠ è½½çš„æ¼”ç¤º
    demo_from_file()
    
    print("\n\n" + "="*70)
    print("ğŸ’¡ é‡è¦æç¤º")
    print("="*70)
    print("\nç´¢å¼•æ–‡ä»¶è¯´æ˜:")
    print("  ğŸ“ data/indexes/demo_kb/")
    print("     â”œâ”€â”€ faiss_index.bin      # FAISSå‘é‡ç´¢å¼•")
    print("     â”œâ”€â”€ documents.pkl        # æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®")
    print("     â”œâ”€â”€ document_ids.json    # æ–‡æ¡£IDæ˜ å°„")
    print("     â””â”€â”€ config.json          # é…ç½®ä¿¡æ¯")
    print("\n  ğŸ“ embedding_cache/        # åµŒå…¥å‘é‡ç¼“å­˜")
    print("     â””â”€â”€ moka-ai_m3e-base_embedding_cache.pkl")
    print("\nä¸‹æ¬¡è¿è¡Œ:")
    print("  - âœ… ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œé€Ÿåº¦æ›´å¿«")
    print("  - âœ… å¯ä»¥åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•")
    print("  - âœ… é¿å…é‡å¤è®¡ç®—åµŒå…¥å‘é‡")
    print("\nè¿è¡Œå…¶ä»–æ¼”ç¤º:")
    print("  python -m src.rag.rag_demo              # RAGå®Œæ•´æµç¨‹æ¼”ç¤º")
    print("="*70)

